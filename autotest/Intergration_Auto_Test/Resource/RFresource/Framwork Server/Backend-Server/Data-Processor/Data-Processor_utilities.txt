*** Settings ***
Resource          Data-Processor_variables.txt
Resource          ../../../Public/public_lib_res_var.txt

*** Keywords ***
Prepare Environment for RDB-23144
    [Arguments]    ${pLocalSnippetsFolder}
    [Documentation]    | Description | get execute result |
    [Tags]    siqi.zeng
    Clear Environment and Trigger Snippets    ${pLocalSnippetsFolder}
    ${rc}=    Execute command    chmod 644 /opt/ygomi/roadDB/jar/cmd/rdb-server-snippetAnalyzer-cmd.jar    return_stdout=False    return_rc=True
    should be equal as integers    ${rc}    0    execute "chmod 644 /opt/ygomi/roadDB/jar/cmd/rdb-server-snippetAnalyzer-cmd.jar" faied!

Check Data Process Execute Flow
    [Documentation]    | Description | check data process execute flow result |
    ...    | input | ${pSnippetsCount}: a snippets count to be a standard |
    [Tags]    siqi.zeng
    #    check the log
    Run Keyword And Continue On Failure    should not be equal as integers    ${logCount}    0
    #    check the saved result in history.processing_files
    Run Keyword And Continue On Failure    should be equal as integers    ${count}    ${sSnippetCount}

rdb-server-snippetAnalyzer-cmd.jar Process Flow
    [Arguments]    ${pData}
    [Documentation]    | Description | 1.post data to data process api to start flow, and wait the flow end |
    ...    | input | |
    ...    | ${pData}| post body |
    [Tags]    siqi.zeng
    #    call the jar
    ${commandName}    set variable    rdb-server-snippetAnalyzer-cmd.jar
    ${data}    set variable    ${pData}
    Post Request to Execution API    ${data}    ${commandName}
    #    wait the flow is done
    Wait the Flow is Done    ${commandName}

Prepare rdb-server-snippetAnalyzer-cmd.jar Process Flow
    [Documentation]    | Description | get rdb-server-snippetAnalyzer-cmd.jar Process result |
    [Tags]    siqi.zeng
    #    get unzip snippets count
    ${unzipCount}    execute command    ls ${gWorkFlowManagerPath}/unzip|wc -l
    set test variable    ${unzipCount}
    #    get json file count
    ${jsonCount}    execute command    find ${gWorkPath}/WorkflowManager/SnippetAnalyzer/json -name "*.json"|wc -l
    set test variable    ${jsonCount}
    #    get traj file count
    ${trajCount}    execute command    find ${gWorkPath}/WorkflowManager/SnippetAnalyzer/traj -name "*.txt"|wc -l
    set test variable    ${trajCount}
    #    get success snippets in db(history.processing_files)
    ${successCount}    Get Snippet Count of T1    /history/snippets?status=1
    set test variable    ${successCount}
    #    get snippets count in db(history.processing_reports)
    Comment    ${sBackendHWaddr}    execute command    ifconfig | awk '/eth/{print $1,$5}'|cut -d ' ' -f 2    # backend's MAC address
    Comment    set suite variable    ${sBackendHWaddr}
    #    get traj data count in db
    create session    backend    ${gDbApiUrl}
    ${response}    get request    backend    /trajectory/visualization
    ${content}    to json    ${response.content}
    ${trajData}    get from dictionary    ${content}    data
    set test variable    ${trajData}
    #    get type 0 log count
    ${tLogCount0}    execute command    find ${gFWLogPath}/rdb-server-snippetAnalyzer-cmd.jar/*/0 -type f -name "*.log"|wc -l
    set test variable    ${tLogCount0}
    #    get type 1 log count
    ${tLogCount1}    execute command    find ${gFWLogPath}/rdb-server-snippetAnalyzer-cmd.jar/*/1 -type f -name "*.log"|wc -l
    set test variable    ${tLogCount1}

Check rdb-server-snippetAnalyzer-cmd.jar Process Flow
    [Documentation]    | Description | check T1 process flow result |
    ...    | input | ${pSnippetsCount}: a snippets count to be a standard |
    [Tags]    siqi.zeng
    #    check whether download and unzip snippet to local
    Run Keyword And Continue On Failure    should be equal as integers    ${unzipCount}    ${sSnippetCount}    /opt/ygomi/roadDB/file_storage/WorkflowManager/unzip snippets counts should be equal as triggered snippet counts
    #    check whether output json and trajectory file and do not delete them
    Run Keyword And Continue On Failure    should be equal as integers    ${jsonCount}    ${sSnippetCount}    debug json file count in /opt/ygomi/roadDB/work/WorkflowManager/SnippetAnalyzer/json should be equal as triggered snippet counts
    Run Keyword And Continue On Failure    should be equal as integers    ${trajCount}    ${sSnippetCount}    debug traj file count in /opt/ygomi/roadDB/work/WorkflowManager/SnippetAnalyzer/traj should be equal as triggered snippet counts
    #    check whether save result to DB
    Run Keyword And Continue On Failure    should be equal as integers    ${successCount}    ${sSnippetCount}    success snippets counts should be equal as triggered snippets counts
    #    check whether update trajectory gps to db(history.processing_files)
    Run Keyword And Continue On Failure    should not be empty    ${trajData}    trajectory gps data in db shuld not be empty
    #    check log
    Run Keyword And Continue On Failure    should be equal as integers    ${tLogCount0}    1    there should be an stdout log in /opt/ygomi/roadDB/file_storage/log/rdb-server-snippetanalyser

rdb-server-foregroundDBMerger-cmd.jar Process Flow
    [Documentation]    | Description | 1.call foregroundDBMerger jar file and check the status, debug file ,sam quality, db result, return SUCCESS if pass |
    ...    | input | gpsskeleton folder |
    [Tags]    siqi.zeng
    #    call the jar
    ${commandName}    set variable    rdb-server-foregroundDBMerger-cmd.jar
    ${data}    set variable    --db http://${gBackendsIp[0]}:8080 --data-processor ${sDataProcessorrUrl}/DataProcessor --foregroundDB-merger-cmd foregroundDBMerger --geometry-merger-cmd logicInfoExtractor --base-dir ${gFileStoragePath} --work-dir ${gWorkPath}/WorkflowManager/ForegroundDBMerger --thread-num 10 --slamsnippet-num 30 --sdorsnippet-num 5000 --limit-num 10000 --division-num 30 --segment-num 30 --type 0 --storage-source LOCAL --confidence 100.0 --domain http://${gBackendsIp[0]}:8080 --find-length 2 --max-length 30 --remote-filestorage http://${gBackendsIp[0]}:8088 --accesskey 111 --secretkey 111 --endpoint --region us-east-1 --bucket ygomi-fws --alg-config /opt/ygomi/roadDB/etc/config --debug
    Post Request to Execution API    ${data}    ${commandName}
    #    wait the flow is done
    Wait the Flow is Done    ${commandName}

Prepare rdb-server-foregroundDBMerger-cmd.jar T20 Result
    [Documentation]    | Description | prepare rdb-server-foregroundDBMerger-cmd.jar process result |
    [Tags]    siqi.zeng
    #    get waiting handle data from db
    ${HWaddr}    execute command    ifconfig | awk '/eth/{print $1,$5}'|cut -d ' ' -f 2    #backend mac address
    ${HWaddr}    upper    ${HWaddr}
    ${snippetCount}    Get Data of T2    /history/processing/fgdb_merger?endpoint_id=${HWaddr}
    set test variable    ${snippetCount}
    #    get debug file count
    ${debugCount}    execute command    find ${gWorkPath}/WorkflowManager/ForegroundDBMerger/foregroundDbMergerDebug -type f|wc -l
    set test variable    ${debugCount}
    #    get json file count
    ${jsonCount}    execute command    find ${gWorkPath}/WorkflowManager/ForegroundDBMerger/foregroundDbMergerJson -type f -name "*.json"|wc -l
    set test variable    ${jsonCount}
    #    get unzip snippets count
    ${unzipCount}    execute command    ls ${gWorkFlowManagerPath}/unzip|wc -l
    set test variable    ${unzipCount}
    #    get quality file count
    ${qualityCount}    execute command    find ${gWorkPath}/WorkflowManager/ForegroundDBMerger/foregroundDbMergerDebug -type d -name "quality"|xargs -i find {} -name "*.txt"|wc -l
    set test variable    ${qualityCount}
    ${snippetCount2}=    evaluate    ${sSnippetCount}*2
    set test variable    ${snippetCount2}
    #    get quality data in db count
    Comment    ${slamDbCount}    Get Snippet Count From Mysql API    /debugdb/sam/get_qualities

Check rdb-server-foregroundDBMerger-cmd.jar T20 Flow
    [Documentation]    | Description | Check rdb-server-foregroundDBMerger-cmd.jar Process Flow |
    ...    | input | ${pSnippetsCount}: a snippets count to be a standard |
    [Tags]    siqi.zeng
    #    check whether save result to DB(history.processing_reports)    DB do not support api to get T2.0 result, so check get processing_reports data now
    Run Keyword And Continue On Failure    should be equal as integers    ${snippetCount}    0    Pending T2.0 data(${snippetCount}) count should be 0
    #    check whether not delete the debug file
    Run Keyword And Continue On Failure    should not be equal as integers    ${debugCount}    0    debug file should not be 0
    Run Keyword And Continue On Failure    should not be equal as integers    ${jsonCount}    0    json file should not be 0
    #    check whether delete unzip snippet
    Run Keyword And Continue On Failure    should be equal as integers    ${unzipCount}    ${sSnippetCount}    unzip snippets should be equal as triggered snippet count
    #    check whether generate sam quality file
    Run Keyword And Continue On Failure    should be equal as integers    ${qualityCount}    ${snippetCount2}    sam quality file should be equal as divisions count
    #    check whether save sam quality data to db    DB'API do not delete data in this table now, wait they update their API
    Comment    should be equal as integers    ${slamDbCount}    ${snippetCount2}

Prepare rdb-server-foregroundDBMerger-cmd.jar T2' Result
    [Arguments]    ${pQueryId}    ${pDataType}=divisions
    [Documentation]    | Description | prepare rdb-server-foregroundDBMerger-cmd.jar T2' result |
    ...    | input | |
    ...    | | ${pQueryId}:divisions id or nodes id |
    ...    | | ${pDataType}--default:divisions, it can be divisions or nodes |
    [Tags]    siqi.zeng
    #    get waiting handle data from db
    ${HWaddr}    execute command    ifconfig | awk '/eth/{print $1,$5}'|cut -d ' ' -f 2    #backend mac address
    ${HWaddr}    upper    ${HWaddr}
    ${snippetCount}    Get Data of T2    pUri=/history/processing/roadMerger?endpoint_id=${HWaddr}
    set test variable    ${snippetCount}
    #    get debug file count
    ${debugCount}    execute command    find ${gWorkPath}/WorkflowManager/ForegroundDBMerger/logicInfoExtractorDebug -type f|wc -l
    set test variable    ${debugCount}
    #    get json file count
    ${jsonCount}    execute command    find ${gWorkPath}/WorkflowManager/ForegroundDBMerger/logicInfoExtractorJson -type f -name "*.json"|wc -l
    set test variable    ${jsonCount}
    #    get unzip snippets count
    ${unzipCount}    execute command    ls ${gWorkFlowManagerPath}/unzip|wc -l
    set test variable    ${unzipCount}
    #    get resource unzip snippets counts
    #    get a division result in DB
    ${infoList}    Get Divisions/Nodes Info    ${pDataType}    /landmarkdb/${pDataType}/data    ${pQueryId}    pVersionUri=/landmarkdb/version
    ${logicCount}    get length    ${infoList}
    set test variable    ${logicCount}

Check rdb-server-foregroundDBMerger-cmd.jar T2' Flow
    [Documentation]    | Description | Check rdb-server-foregroundDBMerger-cmd.jar T2' Flow |
    [Tags]    siqi.zeng
    #    check whether save result to DB(history.processing_reports)    DB do not support api to get T2.0 result, so check get processing_reports data now
    Run Keyword And Continue On Failure    should be equal as integers    ${snippetCount}    0    pending T2' data should be 0
    #    check whether not delete the debug file
    Run Keyword And Continue On Failure    should not be equal as integers    ${debugCount}    0    debug file count should not be 0
    Run Keyword And Continue On Failure    should not be equal as integers    ${jsonCount}    0    json file count should not be 0
    #    check whether delete unzip snippet
    Run Keyword And Continue On Failure    should be equal as integers    ${unzipCount}    ${tSnippetCount}    unzip snippets count should be equal as triggered snippets
    #    check whether save data in db
    Run Keyword And Continue On Failure    should not be equal as integers    ${logicCount}    0    logic data in db should not be 0

Wait the Flow is Done
    [Arguments]    ${pFlowName}    ${pOverTime}=120
    [Documentation]    | Description | wait and Verifies \ flow is done or not by data processor api |
    ...    | input | ${pFlowName}:flow name |
    ...    | | ${pOverTime}:over time,default:120 seconds |
    [Tags]    siqi.zeng
    create session    backend    ${sDataProcessorrUrl}
    : FOR    ${i}    IN RANGE    ${pOverTime}
    \    ${responseGet}    get request    backend    DataProcessor/commands/${pFlowName}/executions    timeout=15
    \    ${responseList}    to json    ${responseGet.content}
    \    should be equal as strings    ${responseGet.status_code}    200    msg=get execute log failed!
    \    ${latestLogDirectory}    get from list    ${responseList}    0
    \    ${latestStatusDirectory}    Get From Dictionary    ${latestLogDirectory}    executionResult
    \    ${responseStatus}    Get From Dictionary    ${latestStatusDirectory}    status
    \    Exit For Loop If    '${responseStatus}'=='done'
    \    sleep    1
    Should Be Equal As Strings    ${responseStatus}    done    ${pFlowName} do not done in ${pOverTime seconds!

Prepare Environment for T2.0
    [Arguments]    ${pSourceSnippetFolder}    ${pGpsSkeletonFolder}
    [Documentation]    | Description | 1.clear backend environment ; 2.trigger snippet; 3.run T1 4.check T1 result |
    ...    | input | ${pSourceSnippetFolder}: snippets resource folder |
    ...    | | \ ${pGpsSkeletonFolder}:gpsskeleton folder |
    [Tags]    siqi.zeng
    [Timeout]
    Clear Environment and Trigger Snippets    ${pSourceSnippetFolder}
    #    import gps skeleton    return_rc=True
    Import GpsSkeleton    ${pGpsSkeletonFolder}
    #    start T1
    rdb-server-snippetAnalyzer-cmd.jar Process Flow    --cmd snippetAnalyzer --base-dir ${gFileStoragePath} --work-dir ${gWorkPath}/WorkflowManager/SnippetAnalyzer --segment-config /usr/local/ygomi/roadDB/algo_res/SegmentConfig.json --db ${gDbApiUrlofDocker} --data-processor http://${gBackendsIp[0]}:${sDataProcessorPort}/DataProcessor --thread-pool-size 10 --db-limit-number 1000 --unzip-dir /WorkflowManager/unzip --storage-source LOCAL --confidence 100.0 --remote-filestorage http://${gBackendsIp[0]}:8088 --accesskey 111 --secretkey 111 --endpoint --region us-east-1 --bucket ygomi-fws --debug
    Prepare rdb-server-snippetAnalyzer-cmd.jar Process Flow
    Check rdb-server-snippetAnalyzer-cmd.jar Process Flow

Prepare Environment for T2'
    [Arguments]    ${pSqlFilePath}    ${pUnzipPath}
    [Documentation]    | Description | 1.clear backend environment ; 2.import sql and copy unzip snippets |
    ...    | input | ${pSqlFilePath}:export_fws_data.sql |
    ...    | | ${pUnzipPath}:unzip snippets path |
    [Tags]    siqi.zeng
    #    clear environment
    Clear Backend Environment
    #    import db sql
    ${str_out}    ${rc}    Execute command    bash ${gToolPath}/db/export_data_fws/import_data_fws.sh -p ${pSqlFilePath} >/tmp/importsql.log    return_stdout=True    return_rc=True
    Should Be Equal As Integers    ${rc}    0    import sql file failed!
    Comment    should contain    ${str_out}    success    import sql file failed!
    #    prepare unzip snippets
    ${rc}    Execute command    cp -r ${pUnzipPath} ${gWorkFlowManagerPath}    return_stdout=False    return_rc=True
    Should Be Equal As Integers    ${rc}    0    copy unzip snippets failed!
    ${tSnippetCount}    Execute command    ls ${pUnzipPath}|wc -l
    set test variable    ${tSnippetCount}

Post Request to Execution API
    [Arguments]    ${pPostData}=    ${pCommandName}=    ${pIsAsyn}=false    ${pToJson}=true
    [Documentation]    | Description | 1.post data to a Restful API and check the post result |
    ...    | input | ${pPostData}:post data |
    ...    | | ${pCommandName}:command name |
    [Tags]    siqi.zeng
    ${header}    create dictionary    Content-Type=application/json    Accept=text/html
    create session    dataprocess    ${sDataProcessorrUrl}
    #    post data to api and get return
    ${response}    Post Request    dataprocess    /DataProcessor/commands/${pCommandName}/executions?asyn=${pIsAsyn}    ${pPostData}
    log    url = /DataProcessor/commands/${pCommandName}/executions?asyn=${pIsAsyn}
    log    ${pPostData}
    set test variable    ${response}
    ${tContent}=    run keyword if    "${pToJson}"=="true"    to json    ${response.content}
    log    ${response.content}
    ${tContentType}=    evaluate    type(${tContent})
    set test variable    ${tContent}
    set test variable    ${tContentType}

Get Request to Execution API
    [Arguments]    ${pExecutionId}    ${pCommandName}=    ${pIsAsyn}=false    ${pToJson}=true
    [Documentation]    | Description | 1.get info of executions |
    ...    | input | \ |
    ...    | ${pCommandName} | command name |
    [Tags]    siqi.zeng
    ${header}    create dictionary    Content-Type=application/json    Accept=text/html
    create session    dataprocess    ${sDataProcessorrUrl}
    #    post data to api and get return
    ${response}    get request    dataprocess    /DataProcessor/commands/${pCommandName}/executions/${pExecutionId}
    log    /DataProcessor/commands/${pCommandName}/executions/${pExecutionId}
    set test variable    ${response}
    ${tContent}=    run keyword if    "${pToJson}"=="true"    ${response.content}
    log    ${response.content}
    ${tContentType}=    evaluate    type(${tContent})
    set test variable    ${tContent}
    set test variable    ${tContentType}

Import GpsSkeleton
    [Arguments]    ${pGpsSkeletonFolder}
    [Documentation]    | Description | 1.import gps skeleton |
    ...    | input | ${pGpsSkeletonFolder}: gps path |
    [Tags]    siqi.zeng
    #    import gpsskeleton
    ${stdout}    ${rc}    execute command    java -jar ${gJavaToolPath}/offline-tool-backendDB-import.jar --dir ${pGpsSkeletonFolder}    return_stdout=True    return_rc=True
    Should Be Equal As Integers    ${rc}    0    import skeleton failed
    should contain    ${stdout}    import skeleton sucessful    import skeleton failed

Prepare Environment for T3.0
    [Arguments]    ${pSourceFolder}
    [Documentation]    | Description | 1.clear backend environment ; 2.trigger snippet; 3.run T1 and T2.0' |
    ...    | input | ${pSourceSnippetFolder}: snippets resource folder |
    Clear Backend Environment
    ${rc}    execute command    mkdir -p ${gUploadPath}    return_stdout=False    return_rc=True
    Should Be Equal As Integers    ${rc}    0    create events/uploads directory failed
    ${rc}    execute command    cp -r \ ${pSourceFolder}/17b43ed9b83e0630a13f61315ab358de \ ${gUploadPath}    return_stdout=False    return_rc=True
    Should Be Equal As Integers    ${rc}    0    uploads files to events/uploads failed
    ${tSnippetCount}    execute command    ls ${gUploadPath} -f |wc -l
    set suite variable    ${tSnippetCount}
    #    Restore mysql
    ${rc}    Execute Command    mysql -udba -pmysql < ${pSourceFolder}/dbbak.sql    return_stdout=False    return_rc=True
    Should Be Equal As Integers    ${rc}    0    restore DB failed
    #    Import Road skeleton
    ${rc}    Execute Command    java -jar \ ${gJavaToolPath}/offline-tool-backendDB-import.jar --json-file ${pSourceFolder}/roadskeleton/roadskeleton.json \ --dir \ ${pSourceFolder}/gpsskeleton    return_stdout=False    return_rc=True
    Should be equal as integers    ${rc}    0    Msg=import \ road skeleton failed
    #    Check snippets if save into DB server    e
    : FOR    ${i}    IN RANGE    50
    \    ${count}    Get Snippet Count of T1    /history/snippets?status=0
    \    Exit For Loop If    '${count}'=='${tSnippetCount}'
    \    sleep    2
    Should Be Equal as integers    ${count}    ${tSnippetCount}    trigger snippets failed!
    #    T1.0 Snippet Analysis
    ${data}    set variable    --cmd snippetAnalyzer --base-dir ${gFileStoragePath} --work-dir ${gWorkPath}/WorkflowManager/SnippetAnalyzer --segment-config /usr/local/ygomi/roadDB/algo_res/SegmentConfig.json --db http://@{gBackendsIp}[0]:8080 --data-processor http://@{gBackendsIp}[0]:9030/DataProcessor --thread-pool-size 10 --db-limit-number 1000 --unzip-dir /WorkflowManager/unzip --storage-source LOCAL --confidence 100.0 --remote-filestorage http://@{gBackendsIp}[0]:8088 --accesskey AKIAJEKO6V5X2HESYPKA --secretkey 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 --endpoint --region us-east-1 --bucket ygomi-fws --debug
    ${commandName}    set variable    rdb-server-snippetAnalyzer-cmd.jar
    Post Request to Execution API    ${data}    ${commandName}
    #    wait the flow is done
    Wait the Flow is Done    rdb-server-snippetAnalyzer-cmd.jar
    #    Check if Snippet Analyzer successfully
    ${successCount}    Get Snippet Count of T1    /history/snippets?processmode=2
    Should Be Equal as integers    ${successCount}    ${tSnippetCount}    Snippet Analyzer failed
    #    Handling T2'
    ${data}    set variable    --db http://@{gBackendsIp}[0]:8080 --data-processor http://@{gBackendsIp}[0]:9030/DataProcessor --foregroundDB-merger-cmd foregroundDBMerger --geometry-merger-cmd logicInfoExtractor --base-dir ${gFileStoragePath} \ --work-dir ${gWorkPath}/WorkflowManager/ForegroundDBMerger --thread-num 10 --slamsnippet-num 30 --sdorsnippet-num 5000 --limit-num 10000 --division-num 30 --segment-num 30 --type 3 --storage-source LOCAL --confidence 100.0 --domain http://@{gBackendsIp}[0]:8080 --find-length 1 --max-length 30 --remote-filestorage http://@{gBackendsIp}[0]:8088 --accesskey 111 --secretkey 111 --endpoint --region us-east-1 --bucket 111 --alg-config \ ${gEnvPathDb}/config --debug
    ${commandName}    set variable    rdb-server-foregroundDBMerger-cmd.jar
    Post Request and Verify By Data Process API    ${data}    ${commandName}
    #    wait the flow is done
    Wait the Flow is Done    rdb-server-foregroundDBMerger-cmd.jar
    : FOR    ${i}    IN RANGE    50
    \    ${code}    Get Process Status from Mysql API    /partial_process/logicdb/status
    \    Exit For Loop If    '${code}'=='200'
    \    sleep    6
    Should Be Equal as integers    ${code}    200    no logic DB is generated

Check rdb-server-genLogicDB-cmd.jar Process Flow
    [Documentation]    | Description | Check rdb-server-genLogicDB-cmd.jar Process Flow |
    log    **************************1. Check if logic DB in the file_storage**************************
    Run Keyword And Continue On Failure    Should be equal As Integers    ${tLogicDBCount}    2    Should contian two bin files logicDB and Master DB
    log    **************************2. Check if logic DB in the work_path **************************
    Run Keyword And Continue On Failure    Should be equal As Integers    ${tExtractLogicDBCount}    2    Should contian two bin files logicDB and Master DB
    log    **************************3. Check if have unzip snippets \ **************************
    Run Keyword And Continue On Failure    Should be equal As Integers    ${tUnzipCount}    ${tSnippetCount}    Should have the same snippets number

rdb-server-genLogicDB-cmd.jar Process Flow
    [Documentation]    | Description | Call genLogicDB jar, it could generate logicDB successfully if pass |
    ${data}    set variable    --db http://@{gBackendsIp}[0]:8080 --data-processor ${sDataProcessorrUrl}/DataProcessor --logic-gen-cmd logicInfoExtractor --data-extractor-cmd rdbDataExtractor --base-dir ${gFileStoragePath} --work-dir ${gWorkPath}/WorkflowManager/GenLogicDB --logicDB-dir /WorkflowManager/logicDB --thread-num 10 --type 3 --storage-source LOCAL --domain http://@{gBackendsIp}[0]:8080 --find-length 2 --max-length 30 --remote-filestorage http://@{gBackendsIp}[0]:8088 --accesskey AKIAJEKO6V5X2HESYPKA --secretkey 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 --endpoint --region us-east-1 --bucket ygomi-fws --debug
    ${commandName}    set variable    rdb-server-genLogicDB-cmd.jar
    Post Request to Execution API    ${data}    ${commandName}
    #    wait the flow is done
    Wait the Flow is Done    rdb-server-genLogicDB-cmd.jar
    ${tLogicDBCount}    Execute Command    find ${gWorkFlowManagerPath}/logicDB -type f | wc -l
    set test variable    ${tLogicDBCount}
    ${tExtractLogicDBCount}    Execute Command    find ${gWorkPath}/WorkflowManager/GenLogicDB/extractorLogicDb -type f | wc -l
    set test variable    ${tExtractLogicDBCount}
    ${tUnzipCount}    execute command    ls ${gWorkFlowManagerPath}/unzip|wc -l
    set test variable    ${tUnzipCount}

rdb-server-vehicleDBGenerate-cmd.jar Process Flow
    [Documentation]    | Description | Call rdb-server-foregroundDBMerger-cmd.jar Process Flow |
    ${data}    set variable    --db http://@{gBackendsIp}[0]:8080 --data-processor ${sDataProcessorrUrl}/DataProcessor --distribute http://@{gBackendsIp}[0]:9100/DistributeVehicledb --foregroundDB-updater-cmd foregroundDBUpdater --vehicleDB-generator-cmd vehicleDBGenerator --data-extractor-cmd rdbDataExtractor --work-dir ${gWorkPath}/WorkflowManager/VehicleDBGenerate --vehicleDB-dir /WorkflowManager/vehicleDB --base-dir ${gFileStoragePath} --thread-num 10 --type 1 --storage-source LOCAL --domain http://@{gBackendsIp}[0]:8080 --find-length 2 --max-length 30 --remote-filestorage http://@{gBackendsIp}[0]:8088 --updater-limit-num 500 --generator-limit-num 500 --step 0 --accesskey 111 --secretkey 111 --endpoint --region us-east-1 --bucket 111 --debug --extract \ --download --alg-config \ ${gEnvPathDb}/config
    ${commandName}    set variable    rdb-server-vehicleDBGenerate-cmd.jar
    Post Request to Execution API    ${data}    ${commandName}
    #    wait the flow is done
    Wait the Flow is Done    rdb-server-vehicleDBGenerate-cmd.jar
    #    Check Whether If the temporary files exist on T2.1
    ${tForegroundDBDebugCount}    Execute Command    find ${gWorkPath}/WorkflowManager/VehicleDBGenerate/foregroudDbUpdaterDebug -type f | wc -l
    set test variable    ${tForegroundDBDebugCount}
    ${tExtractorVehicleDBCount}    Execute Command    find ${gWorkPath}/WorkflowManager/VehicleDBGenerate/extractorVehicleDb -type f | wc -l
    set test variable    ${tExtractorVehicleDBCount}
    #    Check If has vehicleDB to be extracted and distributed
    ${tVehicleDBCount}    Execute Command    find ${gWorkFlowManagerPath}/vehicleDB -name "*.db" | wc -l
    set test variable    ${tVehicleDBCount}
    Comment    ${tEtcVehicleDBCount}    Execute Command    ls /opt/ygomi/roadDB/etc/loc_seg_db_dir_1 | wc -l
    Comment    set test variable    ${tEtcVehicleDBCount}
    #    Check if updating is done
    Comment    ${sBackendHWaddr}    execute command    ifconfig | awk '/eth/{print $1,$5}'|cut -d ' ' -f 2    # backend's MAC address
    Comment    ${tReportUpdaterCount}    Get Data of T2    /history/processing/fgdb_updater?endpoint_id=${sBackendHWaddr}
    Comment    set test variable    ${tReportUpdaterCount}
    #    Check if generate is done
    ${sBackendHWaddr}    execute command    ifconfig | awk '/eth/{print $1,$5}'|cut -d ' ' -f 2    # backend's MAC address
    ${tReportGeneratorCount}    Get Data of T2    /history/processing/vehdb_generator?endpoint_id=${sBackendHWaddr}
    set test variable    ${tReportGeneratorCount}

Check rdb-server-vehicleDBGenerate-cmd.jar Process Flow
    [Documentation]    | Description | Check rdb-server-vehicleDBGenerate-cmd.jar Process Flow |
    log    **************************1. Check if \ has temporary file in foregroundDBDebug**************************
    Run Keyword And Continue On Failure    Should not be equal As Integers    ${tForegroundDBDebugCount}    0    -1    Should has temporary files
    log    **************************2. Check if has temporary files in extractorVehicleDB **************************
    Run Keyword And Continue On Failure    Should not be equal As Integers    ${tExtractorVehicleDBCount}    0    -1    Should has temporary files
    log    **************************3. Check if has vehicleDB \ in file_storage **************************
    Run Keyword And Continue On Failure    Should \ not be equal As Integers    ${tVehicleDBCount}    0    Should contian logicDB and Master DB \ bin files
    Comment    log    **************************4. Check if has distribute vehicleDB in etc **************************
    Comment    Run Keyword And Continue On Failure    Should not be equal As Integers    ${tEtcVehicleDBCount}    0    Should contian ogicDB and Master DB bin files
    log    **************************5. Check if has DB need to be updated or Generated **************************
    Comment    Run Keyword And Continue On Failure    Should not be equal As Integers    ${tReportUpdaterCount}    0    has DB need to be updated
    Run Keyword And Continue On Failure    Should \ be equal As Integers    ${tReportGeneratorCount}    0    No DB need to be generated

Get Process Status from Mysql API
    [Arguments]    ${pUri}
    create session    backend    ${gDbApiUrl}
    ${response}    get request    backend    ${pUri}
    should be equal as integers    ${response.status_code}    200
    ${responseDirectory}    to json    ${response.content}
    ${opsDirectory}    Get From dictionary    ${responseDirectory}    ops
    ${rStatus}    Get From Dictionary    ${opsDirectory}    code
    [Return]    ${rStatus}

Backup Database
    [Documentation]    | Description | Backup Database | \
    ${rc}    Execute command    /opt/ygomi/roadDB/tool/db/export_data_fws/export_data_fws.sh \ -b0 -h127.0.0.1 -p/home/roaddb/    return_stdout=False    return_rc=True
    Run Keyword And Continue On Failure    Should be equal As Integers    ${rc}
    #    /opt/ygomi/roadDB/tool/db/export_data_fws/import_data_fws.sh -r1 -p/home/roaddb/backup_sql -h127.0.0.1
    @{test}    Create List    ${gFileStoragePath}/WorkflowManager    /home/roaddb/backup_sql/*.sql
    Backup Test Results    @{test}

Execute Parameter Analysis Steps
    [Arguments]    ${pJarCmdName}
    [Documentation]    | Description | Execute Parameter Analysis |
    ...    | Input |
    ...    | ${pJarCmdName} | Jar cmd name that need to be executed |
    ...    | Return value |
    ...    | ${rResult} | Return result of executing paramters |
    ...    | ${rCode} | Return code of execution parameters |
    ...    | Expected Result | Execute paramters Analysis \ successfully |
    ${stdout}    ${rc}    execute command    java -jar ${gJavaToolPath}/${pJarCmdName} -h    return_stdout=True    return_rc=True
    @{rResult}    Create List    ${stdout}
    ${stdout}    ${rc}    execute command    java -jar ${gJavaToolPath}/${pJarCmdName} -v    return_stdout=True    return_rc=True
    Insert Into List    ${rResult}    0    ${stdout}
    ${stdout}    ${rc}    Run Keyword If    '${pJarCmdName}'=='rdb-server-vehicleDBGenerate-cmd.jar'    execute command    java -jar ${gJavaToolPath}/${pJarCmdName}    False
    ...    True    True
    ...    ELSE IF    '${pJarCmdName}' == 'rdb-server-genLogicDB-cmd.jar'    execute command    java -jar ${gJavaToolPath}/${pJarCmdName}    True    False
    ...    True
    Insert Into List    ${rResult}    0    ${stdout}
    ${stdout}    ${rc}    Run Keyword If    '${pJarCmdName}'=='rdb-server-vehicleDBGenerate-cmd.jar'    execute command    java -jar ${gJavaToolPath}/${pJarCmdName} -t    False
    ...    True    True
    ...    ELSE IF    '${pJarCmdName}' == 'rdb-server-genLogicDB-cmd.jar'    execute command    java -jar ${gJavaToolPath}/${pJarCmdName} -t    True    False
    ...    True
    Insert Into List    ${rResult}    0    ${stdout}
    ${stdout}    ${rc}    Run Keyword If    '${pJarCmdName}'=='rdb-server-vehicleDBGenerate-cmd.jar'    execute command    java -jar ${gJavaToolPath}/${pJarCmdName} --base-dir    False
    ...    True    True
    ...    ELSE IF    '${pJarCmdName}' == 'rdb-server-genLogicDB-cmd.jar'    execute command    java -jar ${gJavaToolPath}/${pJarCmdName} --base-dir    True    False
    ...    True
    Insert Into List    ${rResult}    0    ${stdout}
    ${stdout}    ${rc}    Run Keyword If    '${pJarCmdName}'=='rdb-server-vehicleDBGenerate-cmd.jar'    execute command    java -jar \ ${gJavaToolPath}/${pJarCmdName} \ --db http://@{gBackendsIp}[0]:1000 --data-processor http://@{gBackendsIp}[0]:9030/DataProcessor --distribute http://@{gBackendsIp}[0]:9100/DistributeVehicledb --foregroundDB-updater-cmd foregroundDBUpdater --vehicleDB-generator-cmd vehicleDBGenerator --data-extractor-cmd rdbDataExtractor --work-dir ${gWorkPath}/WorkflowManager/VehicleDBGenerate --vehicleDB-dir /WorkflowManager/vehicleDB --base-dir ${gFileStoragePath} --thread-num 10 --type 1 --storage-source LOCAL --domain http://@{gBackendsIp}[0]:8080 --find-length 2 --max-length 30 --remote-filestorage http://@{gBackendsIp}[0]:8088 --updater-limit-num 500 --generator-limit-num 500 --step 0 --accesskey 111 --secretkey 111 --endpoint --region us-east-1 --bucket 111 --debug --extract \ --download --alg-config \ /opt/ygomi/roadDB/etc/config    True
    ...    False    True
    ...    ELSE IF    '${pJarCmdName}' == 'rdb-server-genLogicDB-cmd.jar'    execute command    java -jar \ ${gJavaToolPath}/${pJarCmdName} \ --db http://@{gBackendsIp}[0]:1000 --data-processor ${sDataProcessorrUrl}/DataProcessor --logic-gen-cmd logicInfoExtractor --data-extractor-cmd rdbDataExtractor --base-dir ${gFileStoragePath} --work-dir ${gWorkPath}/WorkflowManager/GenLogicDB --logicDB-dir /WorkflowManager/logicDB --thread-num 10 --type 3 --storage-source LOCAL --domain http://@{gBackendsIp}[0]:8080 --find-length 2 --max-length 30 --remote-filestorage http://@{gBackendsIp}[0]:8088 --accesskey AKIAJEKO6V5X2HESYPKA --secretkey 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 --endpoint --region us-east-1 --bucket ygomi-fws --debug    True    False
    ...    True
    Insert Into List    ${rResult}    0    ${stdout}
    [Return]    ${rResult}

Check Result of Parameter Analysis
    [Arguments]    ${pOutput}    ${pJarCmdName}
    [Documentation]    | Description | Check Result of Parameter Analysis |
    ...    | Input |
    ...    | ${pOutput} | Return result after the execution |
    ...    | ${pCode} | Return Code after the execution |
    ...    | Expected Result | Check result successfully |
    ${sSoftwareVersion}    Execute Command    dpkg -l | grep "rdb" | awk 'NR==1{print$3}'
    @{pResult}    Create List    code:500    Missing argument for option: base-dir    Unrecognized option: -t    option is required    ${sSoftwareVersion}
    ...    ${pJarCmdName}
    Log    *******************1. Check if could execute the command line with error port*******************
    Run keyword and Continue on Failure    Should Contain    ${pOutput[0]}    @{pResult}[0]    should contain connect to server failed
    Log    *******************2. Check if \ print \ missing arguments *******************
    Run keyword and Continue on Failure    Should Contain    ${pOutput[1]}    @{pResult}[1]    should contain missing agruments
    Log    *******************3. Check if \ print \ unrecognized option *******************
    Run keyword and Continue on Failure    Should Contain    ${pOutput[2]}    @{pResult}[2]    should contain unrecognized
    Log    *******************4. Check if \ print \ option is required *******************
    Run keyword and Continue on Failure    Should Contain    ${pOutput[3]}    @{pResult}[3]    should print option is required
    Log    *******************5. Check if the software is correct \ *******************
    Run keyword and Continue on Failure    Should Contain    ${pOutput[4]}    @{pResult}[4]    should be equal as the current version
    Log    *******************6. Check if \ print \ jar help information *******************
    Run keyword and Continue on Failure    Should Contain    ${pOutput[5]}    @{pResult}[5]    shoud print jar help information

Check rdb-server-snippetAnalyzer-cmd.jar with No Data
    [Documentation]    | Description | check T1 process flow result |
    ...    | input | ${pSnippetsCount}: a snippets count to be a standard |
    [Tags]    siqi.zeng
    #    check whether download and unzip snippet to local
    Run Keyword And Continue On Failure    should be equal as integers    ${unzipCount}    0    /opt/ygomi/roadDB/file_storage/WorkflowManager/unzip snippets counts should be 0
    #    check whether output json and trajectory file and do not delete them
    Run Keyword And Continue On Failure    should be equal as integers    ${jsonCount}    0    debug json file count in /opt/ygomi/roadDB/work/WorkflowManager/SnippetAnalyzer/json should be 0
    Run Keyword And Continue On Failure    should be equal as integers    ${trajCount}    0    debug traj file count in /opt/ygomi/roadDB/work/WorkflowManager/SnippetAnalyzer/traj should be 0
    #    check whether save result to DB
    Run Keyword And Continue On Failure    should be equal as integers    ${successCount}    0    success snippets counts should be 0
    #    check whether update trajectory gps to db(history.processing_files)
    Run Keyword And Continue On Failure    should be empty    ${trajData}    trajectory gps data in db shuld be empty
    #    check log
    Run Keyword And Continue On Failure    should be equal as integers    ${tLogCount0}    0    there should not be type 0 log
    Run Keyword And Continue On Failure    should be equal as integers    ${tLogCount1}    1    there should a be type 1 log

Check rdb-server-snippetAnalyzer-cmd.jar with No Debug
    [Documentation]    | Description | check T1 process flow result with no debug |
    [Tags]    siqi.zeng
    #    check whether download and unzip snippet to local
    Run Keyword And Continue On Failure    should be equal as integers    ${unzipCount}    ${sSnippetCount}    /opt/ygomi/roadDB/file_storage/WorkflowManager/unzip snippets counts should be equal as triggered snippets count (${sSnippetCount})
    #    check whether output json and trajectory file and do not delete them
    Run Keyword And Continue On Failure    should be equal as integers    ${jsonCount}    0    debug json file count in /opt/ygomi/roadDB/work/WorkflowManager/SnippetAnalyzer/json should be 0
    Run Keyword And Continue On Failure    should be equal as integers    ${trajCount}    0    debug traj file count in /opt/ygomi/roadDB/work/WorkflowManager/SnippetAnalyzer/traj should be 0
    #    check whether save result to DB
    Run Keyword And Continue On Failure    should be equal as integers    ${successCount}    ${sSnippetCount}    success snippets counts should be triggered snippets count(${sSnippetCount})
    #    check whether update trajectory gps to db(history.processing_files)
    Run Keyword And Continue On Failure    should not be empty    ${trajData}    trajectory gps data in db shuld \ not be empty
    #    check log
    Run Keyword And Continue On Failure    should be equal as integers    ${tLogCount0}    1    there should not be type 0 log
    Run Keyword And Continue On Failure    should be equal as integers    ${tLogCount1}    0    there should a be type 1 log

Call Jar Package with Para
    [Arguments]    ${pJarPackage}    ${pPara}    ${pKey}
    [Documentation]    | Description | call jar package with the input parameter and store the result in the dictionary ${sRetResult} |
    ...    | input parameters |
    ...    | ${pJarPackage} | the \ jar package name |
    ...    | ${pPara} | the \ input parameter |
    ...    | ${pKey} | the key in the dictionary ${sRetResult} |
    @{result}    execute command    java -jar ${gJavaToolPath}/${pJarPackage} ${pPara}    return_stdout=True    return_stderr=True    return_rc=True
    set to dictionary    ${sRetResult}    ${pKey}=@{result}

Check Return Value of Para
    [Arguments]    ${pExceptedValue}
    [Documentation]    | Description | Check the return log and return code after executing the jar package |
    ...    | input parameters |
    ...    | ${pExceptedValue} | the expected return info, the input value is separated by |, the first is the key of the dictionary, the second and third are expected return log infor, and the fourth is the expected return code. |
    @{pVExpectedValuelist}    split string    ${pExceptedValue}    |
    ${retValue}    Get From Dictionary    ${sRetResult}    @{pVExpectedValuelist}[0]
    ${retValue[0]}    run keyword if    '@{pVExpectedValuelist}[0]'=='unknownPara'    set variable    ${retValue[1]}
    ...    ELSE    set variable    ${retValue[0]}
    Run Keyword And Continue On Failure    should contain    ${retValue[0]}    @{pVExpectedValuelist}[1]    the return log info does not contain excepted info
    Run Keyword And Continue On Failure    should contain    ${retValue[0]}    @{pVExpectedValuelist}[2]    the return log info does not contain excepted info
    Run Keyword And Continue On Failure    should be equal as integers    ${retValue[2]}    @{pVExpectedValuelist}[3]    the return code is not equal to the excepted code

Clear Environment and Prepare Trigger Data
    [Arguments]    ${pSourceSnippetFolder}    ${pUploadSubPath}=${EMPTY}
    [Documentation]    | Description | clear backend environment and prepare trigger data |
    ...    | input parameters |
    ...    | ${pSourceSnippetFolder} | snippet source path |
    ...    | ${pUploadSubPath} | the subfolder of the upload path |
    Login some Server
    Clear Backend Environment
    ${rc}    execute command    sudo mkdir -p ${gUploadPath}/${pUploadSubPath}    return_stdout=False    return_rc=True
    Should Be Equal As Integers    ${rc}    0    creat upload folder failed!
    ${rc}    execute command    sudo cp \ ${pSourceSnippetFolder}/* ${gUploadPath}/${pUploadSubPath}    return_stdout=False    return_rc=True
    Should Be Equal As Integers    ${rc}    0    copy snippets failed!
    @{sFileList}    SSHLibrary.list files in directory    ${gUploadPath}/${pUploadSubPath}
    @{sSnippetList}    SSHLibrary.list files in directory    ${gUploadPath}/${pUploadSubPath}    pattern=*rtv_slam.out00.gz*
    ${sFileCount}    Get Length    ${sFileList}
    ${sSnippetCount}    Get Length    ${sSnippetList}
    ${sVersionNum}    ${rc}    execute command    dpkg -l | grep "rdb" | awk 'NR==1{print$3}'    return_stdout=True    return_rc=True
    Should Be Equal As Integers    ${rc}    0    Failed to get the version number!
    ${sRetResult}    create dictionary
    set suite variable    @{sFileList}
    set suite variable    @{sSnippetList}
    set suite variable    ${sFileCount}
    set suite variable    ${sSnippetCount}
    set suite variable    ${sVersionNum}
    set suite variable    ${sRetResult}

Check History Snippets
    [Arguments]    ${pUri}    ${pDbApiUrl}=${gDbApiUrl}
    [Documentation]    | Description | get the file path of snippets from history DB |
    ...    | input parameters |
    ...    | ${pUri} | api uri |
    ...    | ${pDbApiUrl} | default:${gDbApiUrl} |
    ...    | return value |
    ...    | ${rDataFilePath} | the file path of snippets |
    ${recordCount}    @{dataList}    Connect DB Api    ${pUri}    ${pDbApiUrl}
    should be equal as integers    ${recordCount}    ${sSnippetCount}
    ${rDataFilePath}    set variable    ${EMPTY}
    : FOR    ${var}    IN    @{dataList}
    \    ${dbFilePath}    Get From Dictionary    ${var}    file_path
    \    ${rDataFilePath}    Catenate    ${rDataFilePath}    ${dbFilePath}
    [Return]    ${rDataFilePath}

Get File Upload Order
    [Arguments]    ${pUri}    ${pSPara}=s1    ${pDbApiUrl}=${gDbApiUrl}
    [Documentation]    | Description | Get the number of imported files and the order of importing files into DB \ |
    ...    | input parameters |
    ...    | ${pUri} | api uri |
    ...    | ${pSPara} | the value of parameter s |
    ...    | ${pDbApiUrl} | default:${gDbApiUrl} |
    ...    | return value |
    ...    | ${rCreateTimeFileList} | the order of importing files,each item is catenated by createtime and file name |
    ${recordCount}    @{dataList}    Connect DB Api    ${pUri}    ${pDbApiUrl}
    ${rCreateTimeFileList}    create list
    : FOR    ${var}    IN    @{dataList}
    \    log    ${var}
    \    ${dbCreateTime}    Get From Dictionary    ${var}    create_time
    \    ${dbFileName}    Get From Dictionary    ${var}    file_name
    \    ${dbFileCreateTime}    Catenate    ${dbCreateTime}    ${dbFileName}
    \    insert into list    ${rCreateTimeFileList}    0    ${dbFileCreateTime}
    log many    ${rCreateTimeFileList}
    Change List Order    ${pSPara}    ${rCreateTimeFileList}
    [Return]    ${rCreateTimeFileList}

Change List Order
    [Arguments]    ${pSpara}    ${pListName}
    [Documentation]    | Description | Modify the order of the input list according to the value of the parameter s |
    ...    | input parameters |
    ...    | ${pSPara} | the value of parameter s |
    ...    | ${pListName} | the input list |
    run keyword if    '${pSpara}'=='s2'    reverse list    ${pListName}
    ...    ELSE IF    '${pSpara}'<>'s3'    sort list    ${pListName}
    ...    ELSE    log    the order of the list is random

Clear Environment and Prepare Skeleton Info
    [Arguments]    ${pSourceSkeletonFolder}
    [Documentation]    | Description | clear backend environment and prepare skeleton data |
    ...    | input parameters |
    ...    | ${pSourceSkeletonFolder} | skeleton source path |
    Login some Server
    Clear Backend Environment
    #get package version
    ${sVersionNum}    ${rc}    execute command    dpkg -l | grep "rdb" | awk 'NR==1{print$3}'    return_stdout=True    return_rc=True
    Should Be Equal As Integers    ${rc}    0    Failed to get the version number!
    set suite variable    ${sVersionNum}
    # gps skeleton
    ${sGpsSkeletonPathofErrFileFormat}    set variable    ${pSourceSkeletonFolder}/err_gps_skeleton_format/
    ${sGpsSkeletonPath}    set variable    ${pSourceSkeletonFolder}
    set suite variable    ${sGpsSkeletonPathofErrFileFormat}
    set suite variable    ${sGpsSkeletonPath}
    #road skeleton
    ${sRoadSkeletonPath}    set variable    ${pSourceSkeletonFolder}/roadskeleton.json
    ${sRoadSkeletonPathofOtherFormat}    set variable    ${pSourceSkeletonFolder}/roadskeleton.txt
    ${ErrRoadSkeletonPath}    set variable    ${pSourceSkeletonFolder}
    ${ErrRoadSkeletonPathofContent}    set variable    ${pSourceSkeletonFolder}/err_roadskeleton.json
    ${UnmatchRoadSkeletonPath}    set variable    ${pSourceSkeletonFolder}/uk_V1.json
    @{sErrRoadSkeleton}    create list    ${ErrRoadSkeletonPath}    ${ErrRoadSkeletonPathofContent}    ${UnmatchRoadSkeletonPath}
    @{sRetCodeofErrRoadSkeleton}    create list    1    134    1
    set suite variable    ${sRoadSkeletonPath}
    set suite variable    ${sRoadSkeletonPathofOtherFormat}
    set suite variable    @{sRetCodeofErrRoadSkeleton}
    set suite variable    @{sErrRoadSkeleton}
    #other variable
    ${sRepairDivisionPath}    set variable    ${gWorkPath}/RepairDivision
    ${sExpectGpsDivisionIds}    set variable    {"division_list":"1490154498373451777,1490154498373451778"}
    ${sExpectRoadDivisionIds}    set variable    {"division_list":"1490154498373451777,1490154498373451778,1490154498373451779,1490154498373451780"}
    set suite variable    ${sRepairDivisionPath}
    set suite variable    ${sExpectGpsDivisionIds}
    set suite variable    ${sExpectRoadDivisionIds}
    ${sExpectGpsDivisionNum}    set variable    2
    ${sExpectRoadDivisionNum}    set variable    4
    set suite variable    ${sExpectGpsDivisionNum}
    set suite variable    ${sExpectRoadDivisionNum}
    #create dict
    ${sRetResult}    create dictionary
    set suite variable    ${sRetResult}

Prepare Checkpoint Data of Skeleton
    [Arguments]    ${pDBName}    ${pPutData}=${EMPTY}
    [Documentation]    | Description | get the DB checkpoint information from the divisions table after importing the skeleton |
    ...    | input parameters |
    ...    | ${pDBName} | the database name |
    ...    | ${pPutData} | the division infor to be inputed when obtaining data from the DB |
    # get version
    ${recordCount}    @{versionDataList}    Connect DB Api    /${pDBName}/version
    ${versionId}    get from dictionary    @{versionDataList}[0]    version_id
    # get divisions info
    ${sDivisionCount}    @{dataList}    Connect DB Api    /${pDBName}/divisions/data?version_id=${versionId}    ${gDbApiUrl}    ${pPutData}
    #get segment id
    ${recordCount}    @{segmentDataList}    Connect DB Api    /${pDBName}/segments?version_id=${versionId}
    ${segmentId}    get from dictionary    @{segmentDataList}[0]    segment_list
    # kml path
    ${kmlName}    run keyword if    '${pDBName}'=='foregrounddb'    set variable    backend_${segmentId}.kml
    ...    ELSE    set variable    landmark_${segmentId}.kml
    ${sKmlPath}    ${rc}    execute command    find ${sRepairDivisionPath} -name ${kmlName}    return_stdout=True    return_rc=True
    Should Be Equal As Integers    ${rc}    0    Failed to find the kml file!
    set suite variable    ${sDivisionCount}
    set suite variable    ${sKmlPath}

Stop Road_ds Service
    [Documentation]    | Description | stop road_ds service |
    @{retRet}    execute command    sudo service road_ds stop    return_stdout=True    return_rc=True
    should be equal as integers    @{retRet}[1]    0

Start Road_ds Service
    [Documentation]    | Description | start road_ds service and backup data|
    write    sudo service road_ds start
    sleep    15
    @{retRet}    execute command    sudo service road_ds status    return_stdout=True    return_rc=True
    should be equal as integers    @{retRet}[1]    0
    should contain    @{retRet}[0]    mysql_jdbc is processing

Clear DB Data
    [Documentation]    | Description | clear db data |
    ${rc}    execute command    ${gToolPath}/db/clear_db_data/allDB_clear.sh >/tmp/log.txt    return_stdout=False    return_rc=True
    Should Be Equal As Integers    ${rc}    0    clear db failed!

Prepare DB Data of Trigger Tool
    [Arguments]    ${pSPara}=s1
    [Documentation]    | Description | get the order of importing files and the snippet files from DB |
    ...    | input parameters |
    ...    | ${pSPara} | the value of parameter s |
    #Get the number of imported files and the order of importing files into DB
    ${dbFileOrderList}    Get File Upload Order    /uploads    ${pSPara}
    #get the file_path of snippet file from history database.
    ${dbsnippetFilePath}    wait until keyword succeeds    1min    5s    Check History Snippets    /history/snippets
    set to dictionary    ${sRetResult}    ${pSPara}order=${dbFileOrderList}    ${pSPara}snippet=${dbsnippetFilePath}

Check Successful Result of Trigger Tool
    [Arguments]    ${pPara}    ${pSPara}=s1
    [Documentation]    | Description | check result when the snippets files are triggered successfully |
    ...    | input parameters |
    ...    | ${pPara} | the key of \ the dictionary that stores the return results |
    ...    | ${pSPara} | the value of parameter s |
    log    ************************1. Check the number and order of the files imported to the DB************************
    ${dbOrderFileList}    Get From Dictionary    ${sRetResult}    ${pSPara}order
    ${dbRecordCount}    get length    ${dbOrderFileList}
    Run Keyword And Continue On Failure    should be equal as integers    ${sFileCount}    ${dbRecordCount}    failed to trigger all files
    ${dbSnippetFilePaths}    Get From Dictionary    ${sRetResult}    ${pSPara}snippet
    Change List Order    ${pSPara}    ${sFileList}
    : FOR    ${i}    IN RANGE    0    ${sFileCount}
    \    log many    ${dbOrderFileList[${i}]}    @{sFileList}[${i}]
    \    Run Keyword And Continue On Failure    should contain    ${dbOrderFileList[${i}]}    @{sFileList}[${i}]    The order of importing files is wrong
    log    ******************************2. Check the snippet files ********************************
    : FOR    ${var}    IN    @{sSnippetList}
    \    Run Keyword And Continue On Failure    should contain    ${dbSnippetFilePaths}    ${var}    The snippet file ${var} did not been triggered successfully
    log    **************************3.Check the return info after importing the snippet files**************************
    Check Return Value of Para    ${pPara}|countSuccess = ${sFileCount}|countFailed = 0|0

Check Result of Importing GPS Skeleton Failure
    [Documentation]    | Description | check results when the gps skeleton is imported unsuccessfully |
    log    **************************1.Check the return info after executing unknown parameter **************************
    Check Return Value of Para    unknownPara|Unrecognized option: -uu|${EMPTY}|0
    log    **************************2.Check the return info after executing empty parameter **************************
    Check Return Value of Para    emptyPara|ParseOptionResult - dir or json-file option is required|${EMPTY}|1
    log    ************************3.Check the return info after executing error gps skeleton path ***********************
    Check Return Value of Para    gpsDirError|retCode1 param dir ${sGpsSkeletonPath}/section_db|import skeleton failed|1
    log    *****************4.Check the return info after importing the GPS skeleton of the error file type *******************
    Check Return Value of Para    gpsFileType|retCode1 param dir ${sGpsSkeletonPathofErrFileFormat}|import skeleton failed|1

Check Result after Successfully Importing GPS Skeleton
    [Documentation]    | Description | check results when the gps skeleton is imported successfully |
    log    **************************1.Check the return info after executing \ jar package with parameter h **************************
    Check Return Value of Para    h|usage: java -jar offline-tool-backendDB-import.jar|-v,--version \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ Show version information.|0
    log    **************************2.Check the return info after executing \ jar package with parameter v **************************
    Check Return Value of Para    v|${sVersionNum}|${EMPTY}|0
    log    *****************************3.Check if kml file is generated ******************************
    Run Keyword And Continue On Failure    should not be empty    ${sKmlPath}    No corresponding KML file was generated!
    log    ***************************4.Check the database for skeleton information ***************************
    Run Keyword And Continue On Failure    should be equal as integers    ${sDivisionCount}    ${sExpectGpsDivisionNum}    The GPS skeleton information stored in the database is incorrect.
    log    *****************5.Check the return log and return code after successfully importing the GPS skeleton ****************
    Check Return Value of Para    gps|exec return 0 command /opt/ygomi/roadDB/tool/DB2KML|export backendDB successful path:/opt/ygomi/roadDB/work_path/RepairDivision|0

Check Result after Successfully Importing Road Skeleton
    [Documentation]    | Description | check result when the road skeleton is imported successfully |
    log    *****************1.Check the return log and return code after successfully importing the GPS skeleton ****************
    Check Return Value of Para    gps|exec return 0 command /opt/ygomi/roadDB/tool/DB2KML|export backendDB successful path:/opt/ygomi/roadDB/work_path/RepairDivision|0
    log    *****************2.Check the return log and return code after successfully importing the Road skeleton ****************
    Check Return Value of Para    road|exec return 0 command /opt/ygomi/roadDB/tool/DB2KML|export landmarkDB successful path:/opt/ygomi/roadDB/work_path/RepairDivision|0
    log    *****************************3.Check if kml file is generated ******************************
    Run Keyword And Continue On Failure    should not be empty    ${sKmlPath}    No corresponding KML file was generated!
    log    ***************************4.Check the database for skeleton information ***************************
    Run Keyword And Continue On Failure    should be equal as integers    ${sDivisionCount}    ${sExpectRoadDivisionNum}    The Road skeleton information stored in the database is incorrect.

Check Result of Importing Road Skeleton Failure
    [Arguments]    ${pErrInfo}
    [Documentation]    | Description | check result when the road skeleton is imported unsuccessfully |
    log    *****************1.Check the return log and return code after successfully importing the GPS skeleton ****************
    Check Return Value of Para    gps${pErrInfo}|exec return 0 command /opt/ygomi/roadDB/tool/DB2KML|export backendDB successful path:/opt/ygomi/roadDB/work_path/RepairDivision|0
    log    *****************2.Check the return log and return code after importing the Road skeleton failure****************
    Check Return Value of Para    roadImportErr${pErrInfo}|rumCmd repairDivision, retCode@{sRetCodeofErrRoadSkeleton}[${pErrInfo}]|import skeleton failed|1

Check Failed Result of Trigger Tool
    [Documentation]    | Description | check result when triggering files with \ error parameters \ |
    log    **************************1.Check the return info after executing jar package with unknown parameter **************************
    Check Return Value of Para    unknownPara|Unrecognized option: -uu|${EMPTY}|0
    log    **************************2.Check the return info after executing \ jar package with illegal DB Url **************************
    Check Return Value of Para    illegalDBUrl|sendOnlineEvent failed: DB error|countSuccess = 0|0
    log    ************************3.Check the return info after executing error gps skeleton path ***********************
    Check Return Value of Para    unknownPath|/opt/ygomi/roadDB/file_storage/events/uploads/unknownpath|fileList.size = 0|0

Check Other Para Result of Trigger Tool
    [Documentation]    | Description | check result after triggering files with other parameters \ |
    log    **************************4.Check the return info after executing parameter h**************************
    Check Return Value of Para    h|usage: java -jar offline-tool-stitching-trigger.jar|-v \ \ \ \ \ \ \ \ \ \ Show version information.|0
    log    **************************5.Check the return info after executing parameter v**************************
    Check Return Value of Para    v|${sVersionNum}|${EMPTY}|0

Post Request and Verify By Data Process API
    [Arguments]    ${pPostData}    ${pCommandName}
    [Documentation]    | Description | 1.post data to a Restful API and check the post result |
    ...    | input | ${pPostData}:post data |
    ...    | | ${pCommandName}:command name |
    [Tags]    siqi.zeng
    ${header}    create dictionary    Content-Type=application/json    Accept=text/html
    create session    dataprocess    ${sDataProcessorrUrl}
    #    check whether start SnippetAnalyzer flow successful
    ${response}    post request    dataprocess    /DataProcessor/commands/${pCommandName}/executions?asyn=false    ${pPostData}
    should be equal as strings    ${response.status_code}    200    msg=execute flow failed!
